# 机器学习概念

- 什么是学习
  - 从人的学习说
  - 起学习理论;从实践经验中总结-在理论上推导;在实践中检验
  - 通过各种手段获取知识或技能的过程
- 机器怎么学习?
  - 处理某个特定的任务，以大量的“经验”为基础
  - 对任务完成的好坏，给予一定的评判标准
  - 通过分析经验数据，任务完成得更好了

# 机器学习主要分类

- 有监督学习:提供数据并提供数据对应结果的机器学习过程。

- 无监督学习:提供数据并且不提供数据对应结果的机器学习过程。

- 强化学习:通过与环境交互并获取延迟返回进而改进行为的学习过程。

  ![3_机器学习基础](http://pic.kiass.top/notes/20210106152806.jpg)

# 监督学习深入介绍



### 监督学习三要素

- 模型
- 策略
- 算法

### 监督学习实现步骤

1. 得到一个有限的训练数据集
2. 确定包含所有学习模型的集合
3. 确定模型选择的准则，也就是学习策略
4. 实现求解最优模型的算法，也就是学习算法
5. 通过学习算法选择最优模型
6. 利用得到的最优模型，对新数据进行预测或分析

<img src="http://pic.kiass.top/notes/20210106162136.png" alt="image-20210106162134796" style="zoom:80%;" />

<img src="http://pic.kiass.top/notes/20210106162147.png" alt="image-20210106162146773" style="zoom:67%;" />

### 模型评估策略

- 模型评估
  - 训练集和测试集
  - 损失函数和经验风险
    - 损失函数用来衡量模型预测误差的大小。
    - 定义:选取模型f为决策函数,对于给定的输入参数X，f(X)为预测结果，Y为真实结果;f(X)和Y之间可能会有偏差，我们就用一个损失函数(loss function)来度量预测偏差的程度，记作 L(Y,f(X))
    - 损失函数越小 , 模型就越好
    - <img src="http://pic.kiass.top/notes/20210106162823.png" alt="image-20210106162822092" style="zoom: 50%;" />
    - 模型f(X)关于训练数据集的平均损失称为经验风险( empirical risk )，记作 $R_{emp}$
    - <img src="http://pic.kiass.top/notes/20210106162959.png" alt="image-20210106162957593" style="zoom:80%;" />
    - 经验风险最小化
    - 样本足够大时，ERM 有很好的学习效果，因为有足够多的“经验”
    - 样本较小时，ERM 就会出现一些问题
  - 训练误差和测试误差
    - 训练误差（training error）是关于训练集的平均损失。
    - 训练误差的大小，可以用来判断给定问题是否容易学习，但本质上**并不重要**
    - 测试误差（testing error）是关于测试集的平均损失。
    - 测试误差真正反映了模型对未知数据的预测能力，这种能力一般被称为**泛化能力**
    - 
- 模型选择
  - 过拟合和欠拟合
    - 过拟合 : 加入了太多的噪音特征 , 泛化能力差
    - 欠拟合 : 模型没很好捕捉数据特征 , "学习"的不够
    - 当模型复杂度增大时，训练误差会逐渐减小并趋向于0;
    - 而测试误差会先减小，达到最小值之后再增大
    - 当模型复杂度过大时，就会发生过拟合;所以模型复杂度应适当
    - <img src="03%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.assets/image-20210106163255916.png" alt="image-20210106163255916" style="zoom:50%;" />
  - 正则化和交叉认证
    - <img src="http://pic.kiass.top/notes/20210106163716.png" alt="image-20210106163715545" style="zoom:80%;" />
    - 奥卡姆剃刀 : 如无必要 , 选择最简单的模型
    - <img src="http://pic.kiass.top/notes/20210106163644.png" alt="image-20210106163642983" style="zoom: 80%;" />



- 分类和回归

  - 分类问题
  - 分类问题预测数据属于哪一类别。 — —离散
  - 回归问题根据数据预测一个数值。 — ―连续
  - 通俗地讲，分类问题就是预测数据属于哪一种类型，就像上面的房屋出售预测，通过大量数据训练模型，然后去预测某个给定房屋能不能出售出去，属于能够出售类型还是不能出售类型。
  - 回归问题就是预测一个数值，比如给出房屋一些特征，预测房价
  - 分类问题可以用很多学习方法来解决，比如k近邻、决策树、感知机、逻辑斯谛回归、支撑向量机、朴素贝叶斯法、神经网络等

- 精确率和召回率

- 评价分类器性能的指标一般是分类准确率(accuracy)，它定义为分类器对测试集正确分类的样本数与总样本数之比 , 对于二类分类问题，常用的评价指标是精确率(precision)与召回率(recall)

  - TP:将正类预测为正类的数目
  - FN:将正类预测为负类的数目
  - FP:将负类预测为正类的数目
  - TN:将负类预测为负类的数目

- 精确率

  - 概念 : 所有**预测**为正类的数据中,预测正确的比例
  - $P = \dfrac{TP}{TP+FP}$

- 召回率

  - 概念 : 所有**实际**为正类的数据中,被正确的预测找出来的比例
  - $R = \dfrac{TP}{TP+FN}$

  

  

### 模型求解算法（学习算法）

- 梯度下降法

  - <img src="http://pic.kiass.top/notes/20210106164311.png" alt="image-20210106164310622" style="zoom:80%;" />
  - <img src="http://pic.kiass.top/notes/20210106164350.png" alt="image-20210106164350001" style="zoom:80%;" />

- 牛顿法和拟牛顿法

  - ![image-20210106164247735](http://pic.kiass.top/notes/20210106164249.png)

  

  

  

  





